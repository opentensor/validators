import torch
import numpy as np
from typing import Union

def is_nsfw(self, message, bound_score=0.5, return_score=False) -> Union[bool, float]:
    """Check if the message contains hateful content.

    Args:
        message (str):
            The message that we check if we should filter out.
        bound_score (float):
            Threshold for the logit score to filter out the message.
        return_score (bool):
            Whether to return the logit score for the message being unsafe.
    Returns:
        result (bool if return_score is False, float if return_score is True):
            bool: True indicates we should filter out the result, false indicates the result is safe.
            float: The logit score for the message being unsafe.

    """
    tokenized = self.nsfw_filter_tokenizer(message)
    input_ids = tokenized["input_ids"]
    score = -1000
    # The model can only support 512 tokens at a time, so we have to break up the check
    # if there are too many tokens in a single message.
    while len(input_ids) > 0:
        _input_ids = input_ids[:512]

        with torch.no_grad():
            output = self.nsfw_filter_model(torch.tensor([_input_ids]).to(self.device))

        nothate, hate = output.logits[0].tolist()
        if return_score:
            # Return the max logit score across the message.
            score = max(hate, score)
        elif hate > bound_score or nothate < bound_score:
            # Filter out if the logit score is out of bound.
            return True

        input_ids = input_ids[512:]

    if return_score:
        return score
    else:
        return False
    
def mean_pooling(model_output, attention_mask):
    """Applies mean pooling to the token embeddings generated by the model.
    Args:
        model_output (torch.Tensor): Embedding model output, where the first element contains token embeddings.
        attention_mask (torch.Tensor): Attention mask to indicate valid tokens.
    Returns:
        torch.Tensor: Mean-pooled representation of the token embeddings.
    Notes:
        - The function calculates the mean-pooled representation using the attention mask for valid tokens.
        - Input_mask_expanded is created by expanding the attention mask to match the size of token embeddings.
        - The result is obtained by summing the element-wise multiplication of embeddings and input_mask_expanded,
            and dividing it by the sum of input_mask_expanded after clamping its values to a minimum of 1e-9.
    """
    token_embeddings = model_output[0]
    input_mask_expanded = (
        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    )
    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(
        input_mask_expanded.sum(1), min=1e-9
    )

def get_embedding(self, message: str) -> "torch.FloatTensor":
    """Runs a forward pass through the model.
    Args:
        message (:obj:`str`):
            text message to be encoded.
    Returns:
        embedding (:obj:`torch.FloatTensor`):
            Embedding for the message.
    """
    encoded_input = self.relevance_tokenizer(
        message,
        padding=True,
        truncation=True,
        return_overflowing_tokens=True,
        return_tensors="pt",
    ).to(self.device)

    # Pop the overflow mapping from the input to maintain the expected { input_ids, mask } format of the model
    _ = encoded_input.pop("overflow_to_sample_mapping")

    with torch.no_grad():
        embeddings = self.relevance_model(**encoded_input)

    sentence_embeddings = mean_pooling(embeddings, encoded_input["attention_mask"])
    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)
    batch_representation = torch.mean(sentence_embeddings, dim=0)
    return batch_representation

def RMSE(emb1: torch.FloatTensor, emb2: torch.FloatTensor) -> torch.FloatTensor:
    """Calculate the RMSE distance for the 2 embeddings.
    Args: 
        emb1 (:obj:`torch.FloatTensor`):
            The first tensor embedding.
        emb2 (:obj:`torch.tensor`):
            The second tensor embedding.
    Returns:
        diff (:obj:`torch.FloatTensor`):
            The RMSE difference in the 2 embeddings. 
    """
    return (( emb1 - emb2 )**2).mean()**0.5

def is_relevant(self, prompt:str, completion: str, is_answer: bool, answer_bound:float = 0.0275, prompt_bound:float = 0.0325 ) -> bool:
    """Check the relevancy between prompt and completion.
    Args: 
        prompt (:type:`str`):
            The prompt string for the completion.
        completion (:type:`str`):
            The completion for the prompt.
        is_answer (:type:`bool`):
            If the completion is for the a follow up OR an answer.
    
    Returns:
        is_relevant (:type:`bool`):
            True if the prompt and completion are considered relating to each other, else False
    """
    
    completion_embedding = get_embedding(self, completion)
    prompt_embedding = get_embedding(self, prompt)
    diff = RMSE( completion_embedding, prompt_embedding)
    if is_answer:
        return (diff < answer_bound).bool()
    else:
        return (diff < prompt_bound).bool() 