import datasets
import pandas as pd


_DESCRIPTION = """\
Openvalidators dataset is a collection of data generated by openvalidators 
in the bittensor network.


The openvalidators dataset is a collection of data generated by the bittensor community in the bittensor network using \
openvalidators (https://github.com/opentensor/validators). It consists of two main components: the analytical raw \
dataset and the mining dataset.

The analytical raw dataset is derived from the raw data collected by the openvalidators code and processed using wandb. \
It provides detailed insights into the behavior and performance of the openvalidators within the network. \
Researchers and data scientists can use this dataset to analyze the efficiency and stability of the openvalidators and \
identify patterns or trends.

The mining dataset is derived from the analytical raw dataset and is specifically designed for bittensor miners. \
It can be utilized to fine-tune mining models, helping miners optimize their strategies and increase their incentives within the network.
"""

_HOMEPAGE = "https://github.com/opentensor/validators"

_LICENSE = "MIT License"

_BASE_URL = "https://huggingface.co/datasets/pedroferreira/test-release/raw/main"

_URLS = {
    "v0.1.0": f"{_BASE_URL}/v1.0.1/raw_data/51odtuqm_openvalidators_dataset.parquet",
    "v1.0.0": f"{_BASE_URL}/v1.0.1/data/51odtuqm_openvalidators_dataset.parquet",
}

class OpenValidatorsDatasetConfig(datasets.GeneratorBasedBuilder):
    """OpenValidators dataset is a collection of data generated by openvalidators in the bittensor network."""

    VERSION = datasets.Version("1.0.0")

    BUILDER_CONFIGS = [
        datasets.BuilderConfig(
            name="v0.1.0",
            version = VERSION,
            description="Version 0.1.0 of the openvalidators dataset",
        ),
        datasets.BuilderConfig(
            name="v1.0.0",
            version=VERSION,
            description="Version 0.1.0 of the openvalidators dataset",
        )
    ]

    DEFAULT_CONFIG_NAME = "v1.0.0"

    def _info(self):
        features = datasets.Features(
            {
                "run_id": datasets.Value("string"),
                "answer_rewards": datasets.Sequence(datasets.Value("float32")),
                "moving_averaged_scores": datasets.Sequence(datasets.Value("float32")),
                "_step": datasets.Value("int32"),
                "gating_scorings": datasets.Sequence(datasets.Value("float32")),
                "answer_times": datasets.Sequence(datasets.Value("float32")),
                "followup_uids": datasets.Sequence(datasets.Value("int32")),
                "answer_completions": datasets.Sequence(datasets.Value("string")),
                "followup_completions": datasets.Sequence(datasets.Value("string")),
                "followup_rewards": datasets.Sequence(datasets.Value("float32")),
                "answer_uids": datasets.Sequence(datasets.Value("int32")),
                "followup_times": datasets.Sequence(datasets.Value("float32")),
                "step_length": datasets.Value("float32"),
                "_runtime": datasets.Value("float64"),
                "base_prompt": datasets.Value("string"),
                "best_answer": datasets.Value("string"),
                "answer_prompt": datasets.Value("string"),
                "gating_loss": datasets.Value("float64"),
                "best_followup": datasets.Value("string"),
                "_timestamp": datasets.Value("string"),
                "block": datasets.Value("float64"),
                "set_weights": datasets.Value("string"),
            }
        )

        return datasets.DatasetInfo(
            description=_DESCRIPTION,
            features=features,
            homepage=_HOMEPAGE,
            license=_LICENSE,
        )

    def _split_generators(self, dl_manager: datasets.DownloadManager):
        data_dir = dl_manager.download_and_extract(_URLS)
        return [
            datasets.SplitGenerator(
                name=datasets.Split.TEST,
                # These kwargs will be passed to _generate_examples
                gen_kwargs={
                    "filepath": data_dir
                },
            ),
        ]

    def _generate_examples(self, filepath):
        df = pd.read_parquet(filepath)

        for row in df.iterrows():
            yield row


ds = datasets.load_dataset('pedroferreira/test-release', data_files={ 'test': 'v1.0.1/raw_data/*'})

dataset_builder = OpenValidatorsDatasetConfig()
dataset_builder.download_and_prepare()
dataset = dataset_builder.as_dataset()